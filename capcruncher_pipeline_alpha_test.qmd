---
title: "CapCruncher Pipeline Alpha Testing"
author: "Alastair Smith"
date: today
format:
  html:
    toc: true
    theme: cosmo
    embed-resources: true
    code-block-background: true
    highlight-style: github
    code-fold: true
execute:
  echo: true
  eval: false

---

# Current Status

This is still in alpha testing so there are still some bugs and missing features.

## Known issues

* BUG: Out of jobs ready to be started, but not all files built yet. Please check https://github.com/snakemake/snakemake/issues/823 for more information - Best solution is to just re-run the pipeline.

* BUG: The pipeline will fail if there are no reads left after filtering. This is a known issue and will be fixed in the next release.




# Installation - Alpha Testing

There are two main ways currently to run the new pipeline:

A) Install into a conda environment and run directly from this.

B) Install into a very minimal conda env and then run the pipeline using a singularity container.

## 0. Prerequisites

### 0.1 Download the GitHub repo development branch

```bash
git clone https://github.com/sims-lab/CapCruncher.git
cd CapCruncher
git checkout develop
```


## A. Fully featured conda environment

**Note**: I highly recommend using mamba for the env generation, it is substantially faster than conda.

```bash
mamba env create -f environment.yml
conda activate cc
```

## B. Minimal conda environment

```bash
mamba create -n cc pip "python==3.10"
conda activate cc
```

## Install CapCruncher

**Note:** Whilst not essential I would install the stats, plotting and experimental dependecies as well as the core package. This is what I do for my own testing.

```bash
pip install .[stats,plotting,experimental]
```

## (Optional) Set-up a Snakemake profile

This is not essential but it will make running the pipeline much easier by submitting jobs to the cluster automatically and using pre-set parameters.

**Note:** Cookiecutter is required for this step. This can be installed using `pip install cookiecutter`.


### For SLURM based clusters:

```bash
# create config directory that snakemake searches for profiles (or use something else)
profile_dir="${HOME}/.config/snakemake"
mkdir -p "$profile_dir"
# use cookiecutter to create the profile in the config directory
template="gh:Snakemake-Profiles/slurm"
cookiecutter --output-dir "$profile_dir" "$template"
```

### For SGE based clusters:

**Note:** I have no way of testing this so it may not work.

```bash
mkdir -p ~/.config/snakemake
cd ~/.config/snakemake
cookiecutter https://github.com/Snakemake-Profiles/sge.git
```

### My current profiles look like this:

```
/home/a/asmith/.config/snakemake/slurm/
├── config.yaml
├── CookieCutter.py
├── __pycache__
│   ├── CookieCutter.cpython-310.pyc
│   ├── CookieCutter.cpython-311.pyc
│   ├── slurm_utils.cpython-310.pyc
│   └── slurm_utils.cpython-311.pyc
├── settings.json
├── slurm-jobscript.sh
├── slurm-sidecar.py
├── slurm-status.py
├── slurm-submit.py
└── slurm_utils.py
```

`settings.json`:

```json
{
    "SBATCH_DEFAULTS": "--partition=short --time=0-01:00:00 --mem=3G",
    "CLUSTER_NAME": "",
    "CLUSTER_CONFIG": ""
}
```

`config.yaml`:

```yaml

cluster-sidecar: "slurm-sidecar.py"
cluster-cancel: "scancel"
restart-times: "0"
jobscript: "slurm-jobscript.sh"
cluster: "slurm-submit.py"
cluster-status: "slurm-status.py"
max-jobs-per-second: "10"
max-status-checks-per-second: "10"
local-cores: 1
latency-wait: "5"
use-conda: "True"
use-singularity: "False"
singularity-args: -B /ceph  -B /databank
jobs: "50"
printshellcmds: "True"
retries: 3

# Example resource configuration
# default-resources:
#   - runtime=100
#   - mem_mb=6000
#   - disk_mb=1000000
# # set-threads: map rule names to threads
# set-threads:
#   - single_core_rule=1
#   - multi_core_rule=10
# # set-resources: map rule names to resources in general
# set-resources:
#   - high_memory_rule:mem_mb=12000
#   - long_running_rule:runtime=1200

```

**Note**: The singularity-args are required to mount the data directories into the container. e.g.

```bash
singularity-args: -B /ceph  -B /databank
```

Gives the container access to the `/ceph` and `/databank` directories on the cluster. The current working directory is also mounted into the container by default. You can add additional directories by adding more `-B` flags. Obviously this will be different for each cluster so you'll need your own defaults.

# Pipeline Configuration


## 1. Generate a config file

The pipeline is configured using a YAML file. This file is passed to the pipeline using the `--config` flag. The pipeline will look for a file called `capcruncher_config.yml` in the current working directory by default. This can be overridden using the `--config` flag.

I've added in a utility to generate a custom config via command line prompts. I would highly recommend using this as the testing is performed using this method and it will ensure that the config is valid.

```bash
capcruncher pipeline-config
```

Just follow the prompts and it will generate a config file for you. Any errors can be corrected by editing the config file directly.

This will generate a config file called `capcruncher_config.yml` in a folder with the current date, project name and assay type in the current working directory e.g. `2023-05-23-rb-tiled-c`.

## (Optional) 2. Generate a design file

**Note**: This is completely optional as the pipeline will do some basic sample name comparison to generate a basic design file. However, this will not be as accurate as a manually generated design file.

**Note:** I will add an option to automatically generate a design file but this is not yet implemented.

A design file is optional and only used for comparisons between Capture-C and Tri-C data. It is a tab delimited file with the following columns:

- `sample`: The name of the FASTQ file (without the _R1.fastq.gz or _2.fastq.gz suffix)
- `condition`: The Group that the sample belongs to.

Provide the path to this file in the config file under the `design` key.


## 3. Ensure that the FASTQ files are in the working directory

The pipeline will look for FASTQ files in the current working directory. It will look for files with the following suffixes:

- `_R1.fastq.gz`
- `_2.fastq.gz`

Eventually a design file will also be able to be used. This is not yet implemented.

**Note**: Symlinks are also supported. I would recommend using the absolute path to the FASTQ files to avoid any issues.


# Running the pipeline

The pipeline is entirely Snakemake based now so you can see their [documentation](https://snakemake.readthedocs.io/en/stable/) and add any additional flags that you want to use.

## A. Running the pipeline locally (within the conda environment exclusively)

```bash
capcruncher pipeline -c <NUMBER OF CORES>
```

## B. Running the pipeline on a cluster (within the conda environment exclusively)

```bash
capcruncher pipeline -c <NUMBER OF CORES> --profile <PROFILE NAME>
```

Example:

```bash
capcruncher pipeline -c 10 --profile slurm
```

## C. Running the pipeline using the singularity container

Assuming the profile is set-up correctly this is as simple as:

```bash
capcruncher pipeline -c <NUMBER OF CORES> --profile <PROFILE NAME> --use-singularity
```

You can also use the container locally by adding the `--use-singularity` flag to the command. e.g.

**Note**: You need to add the custom singularity arguments to the command as well to bind the data directories to the container.

```bash
capcruncher pipeline -c 10 --use-singularity --singularity-args " -B /ceph -B /databank "
```


# Output

## 1. Example output

The pipeline will generate a folder called `capcruncher_output` in the current working directory. This will contain the following files:

** Note **: This is subject to change as the pipeline is still in development.

```
── interim
│   ├── annotate
│   │   └── exclude.bed
│   ├── comparisons
│   │   ├── summaries_and_subtractions
│   │   │   ├── A-B.mean-subtraction.Slc25A37.bedgraph
│   │   │   ├── A.mean-summary.Slc25A37.bedgraph
│   │   │   ├── B-A.mean-subtraction.Slc25A37.bedgraph
│   │   │   └── B.mean-summary.Slc25A37.bedgraph
│   │   ├── summaries_and_subtractionsA-B.mean-subtraction.Slc25A37.bedgraph
│   │   ├── summaries_and_subtractionsA.mean-summary.Slc25A37.bedgraph
│   │   ├── summaries_and_subtractionsB-A.mean-subtraction.Slc25A37.bedgraph
│   │   └── summaries_and_subtractionsB.mean-summary.Slc25A37.bedgraph
│   ├── fastq
│   │   ├── deduplicated
│   │   │   ├── SAMPLE-A_REP1
│   │   │   │   ├── SAMPLE-A_REP1_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP1_part0_2.fastq.gz
│   │   │   ├── SAMPLE-A_REP2
│   │   │   │   ├── SAMPLE-A_REP2_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP2_part0_2.fastq.gz
│   │   │   ├── SAMPLE-B_REP1
│   │   │   │   ├── SAMPLE-B_REP1_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-B_REP1_part0_2.fastq.gz
│   │   │   └── SAMPLE-B_REP2
│   │   │       ├── SAMPLE-B_REP2_part0_1.fastq.gz
│   │   │       └── SAMPLE-B_REP2_part0_2.fastq.gz
│   │   ├── flashed
│   │   │   ├── SAMPLE-A_REP1
│   │   │   │   ├── SAMPLE-A_REP1_part0.extendedFrags.fastq.gz
│   │   │   │   ├── SAMPLE-A_REP1_part0.hist
│   │   │   │   ├── SAMPLE-A_REP1_part0.histogram
│   │   │   │   ├── SAMPLE-A_REP1_part0.notCombined_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP1_part0.notCombined_2.fastq.gz
│   │   │   ├── SAMPLE-A_REP2
│   │   │   │   ├── SAMPLE-A_REP2_part0.extendedFrags.fastq.gz
│   │   │   │   ├── SAMPLE-A_REP2_part0.hist
│   │   │   │   ├── SAMPLE-A_REP2_part0.histogram
│   │   │   │   ├── SAMPLE-A_REP2_part0.notCombined_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP2_part0.notCombined_2.fastq.gz
│   │   │   ├── SAMPLE-B_REP1
│   │   │   │   ├── SAMPLE-B_REP1_part0.extendedFrags.fastq.gz
│   │   │   │   ├── SAMPLE-B_REP1_part0.hist
│   │   │   │   ├── SAMPLE-B_REP1_part0.histogram
│   │   │   │   ├── SAMPLE-B_REP1_part0.notCombined_1.fastq.gz
│   │   │   │   └── SAMPLE-B_REP1_part0.notCombined_2.fastq.gz
│   │   │   └── SAMPLE-B_REP2
│   │   │       ├── SAMPLE-B_REP2_part0.extendedFrags.fastq.gz
│   │   │       ├── SAMPLE-B_REP2_part0.hist
│   │   │       ├── SAMPLE-B_REP2_part0.histogram
│   │   │       ├── SAMPLE-B_REP2_part0.notCombined_1.fastq.gz
│   │   │       └── SAMPLE-B_REP2_part0.notCombined_2.fastq.gz
│   │   ├── rebalanced
│   │   │   ├── SAMPLE-A_REP1
│   │   │   │   ├── flashed
│   │   │   │   │   └── SAMPLE-A_REP1_part0_flashed_1.fastq.gz
│   │   │   │   └── pe
│   │   │   │       ├── SAMPLE-A_REP1_part0_pe_1.fastq.gz
│   │   │   │       └── SAMPLE-A_REP1_part0_pe_2.fastq.gz
│   │   │   ├── SAMPLE-A_REP2
│   │   │   │   ├── flashed
│   │   │   │   │   └── SAMPLE-A_REP2_part0_flashed_1.fastq.gz
│   │   │   │   └── pe
│   │   │   │       ├── SAMPLE-A_REP2_part0_pe_1.fastq.gz
│   │   │   │       └── SAMPLE-A_REP2_part0_pe_2.fastq.gz
│   │   │   ├── SAMPLE-B_REP1
│   │   │   │   ├── flashed
│   │   │   │   │   └── SAMPLE-B_REP1_part0_flashed_1.fastq.gz
│   │   │   │   └── pe
│   │   │   │       ├── SAMPLE-B_REP1_part0_pe_1.fastq.gz
│   │   │   │       └── SAMPLE-B_REP1_part0_pe_2.fastq.gz
│   │   │   └── SAMPLE-B_REP2
│   │   │       ├── flashed
│   │   │       │   └── SAMPLE-B_REP2_part0_flashed_1.fastq.gz
│   │   │       └── pe
│   │   │           ├── SAMPLE-B_REP2_part0_pe_1.fastq.gz
│   │   │           └── SAMPLE-B_REP2_part0_pe_2.fastq.gz
│   │   ├── split
│   │   │   ├── SAMPLE-A_REP1
│   │   │   │   ├── SAMPLE-A_REP1_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP1_part0_2.fastq.gz
│   │   │   ├── SAMPLE-A_REP2
│   │   │   │   ├── SAMPLE-A_REP2_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-A_REP2_part0_2.fastq.gz
│   │   │   ├── SAMPLE-B_REP1
│   │   │   │   ├── SAMPLE-B_REP1_part0_1.fastq.gz
│   │   │   │   └── SAMPLE-B_REP1_part0_2.fastq.gz
│   │   │   └── SAMPLE-B_REP2
│   │   │       ├── SAMPLE-B_REP2_part0_1.fastq.gz
│   │   │       └── SAMPLE-B_REP2_part0_2.fastq.gz
│   │   └── trimmed
│   │       ├── SAMPLE-A_REP1
│   │       │   ├── SAMPLE-A_REP1_part0_1.fastq.gz_trimming_report.txt
│   │       │   └── SAMPLE-A_REP1_part0_2.fastq.gz_trimming_report.txt
│   │       ├── SAMPLE-A_REP2
│   │       │   ├── SAMPLE-A_REP2_part0_1.fastq.gz_trimming_report.txt
│   │       │   └── SAMPLE-A_REP2_part0_2.fastq.gz_trimming_report.txt
│   │       ├── SAMPLE-B_REP1
│   │       │   ├── SAMPLE-B_REP1_part0_1.fastq.gz_trimming_report.txt
│   │       │   └── SAMPLE-B_REP1_part0_2.fastq.gz_trimming_report.txt
│   │       └── SAMPLE-B_REP2
│   │           ├── SAMPLE-B_REP2_part0_1.fastq.gz_trimming_report.txt
│   │           └── SAMPLE-B_REP2_part0_2.fastq.gz_trimming_report.txt
│   ├── filtering
│   │   └── repartitioned
│   │       ├── SAMPLE-A_REP1
│   │       │   ├── flashed
│   │       │   │   └── SAMPLE-A_REP1_part0_flashed.slices.parquet
│   │       │   └── pe
│   │       │       └── SAMPLE-A_REP1_part0_pe.slices.parquet
│   │       ├── SAMPLE-A_REP2
│   │       │   ├── flashed
│   │       │   │   └── SAMPLE-A_REP2_part0_flashed.slices.parquet
│   │       │   └── pe
│   │       │       └── SAMPLE-A_REP2_part0_pe.slices.parquet
│   │       ├── SAMPLE-B_REP1
│   │       │   ├── flashed
│   │       │   │   └── SAMPLE-B_REP1_part0_flashed.slices.parquet
│   │       │   └── pe
│   │       │       └── SAMPLE-B_REP1_part0_pe.slices.parquet
│   │       └── SAMPLE-B_REP2
│   │           ├── flashed
│   │           │   └── SAMPLE-B_REP2_part0_flashed.slices.parquet
│   │           └── pe
│   │               └── SAMPLE-B_REP2_part0_pe.slices.parquet
│   ├── pileups
│   │   └── bedgraphs
│   │       ├── SAMPLE-A_REP1
│   │       │   ├── norm
│   │       │   │   └── SAMPLE-A_REP1_Slc25A37.bedgraph
│   │       │   └── raw
│   │       │       └── SAMPLE-A_REP1_Slc25A37.bedgraph
│   │       ├── SAMPLE-A_REP2
│   │       │   ├── norm
│   │       │   │   └── SAMPLE-A_REP2_Slc25A37.bedgraph
│   │       │   └── raw
│   │       │       └── SAMPLE-A_REP2_Slc25A37.bedgraph
│   │       ├── SAMPLE-B_REP1
│   │       │   ├── norm
│   │       │   │   └── SAMPLE-B_REP1_Slc25A37.bedgraph
│   │       │   └── raw
│   │       │       └── SAMPLE-B_REP1_Slc25A37.bedgraph
│   │       └── SAMPLE-B_REP2
│   │           ├── norm
│   │           │   └── SAMPLE-B_REP2_Slc25A37.bedgraph
│   │           └── raw
│   │               └── SAMPLE-B_REP2_Slc25A37.bedgraph
│   ├── qc
│   │   ├── alignment_raw
│   │   │   ├── SAMPLE-A_REP1.txt
│   │   │   ├── SAMPLE-A_REP2.txt
│   │   │   ├── SAMPLE-B_REP1.txt
│   │   │   └── SAMPLE-B_REP2.txt
│   │   └── fastqc
│   │       ├── SAMPLE-A_REP1_1_fastqc.html
│   │       ├── SAMPLE-A_REP1_1_fastqc.zip
│   │       ├── SAMPLE-A_REP1_2_fastqc.html
│   │       ├── SAMPLE-A_REP1_2_fastqc.zip
│   │       ├── SAMPLE-A_REP2_1_fastqc.html
│   │       ├── SAMPLE-A_REP2_1_fastqc.zip
│   │       ├── SAMPLE-A_REP2_2_fastqc.html
│   │       ├── SAMPLE-A_REP2_2_fastqc.zip
│   │       ├── SAMPLE-B_REP1_1_fastqc.html
│   │       ├── SAMPLE-B_REP1_1_fastqc.zip
│   │       ├── SAMPLE-B_REP1_2_fastqc.html
│   │       ├── SAMPLE-B_REP1_2_fastqc.zip
│   │       ├── SAMPLE-B_REP2_1_fastqc.html
│   │       ├── SAMPLE-B_REP2_1_fastqc.zip
│   │       ├── SAMPLE-B_REP2_2_fastqc.html
│   │       └── SAMPLE-B_REP2_2_fastqc.zip
│   └── statistics
│       ├── cis_and_trans_reporters
│       │   ├── cis_and_trans_reporters.csv
│       │   └── data
│       │       ├── SAMPLE-A_REP1.reporter.stats.csv
│       │       ├── SAMPLE-A_REP2.reporter.stats.csv
│       │       ├── SAMPLE-B_REP1.reporter.stats.csv
│       │       └── SAMPLE-B_REP2.reporter.stats.csv
│       ├── deduplication
│       │   ├── data
│       │   │   ├── SAMPLE-A_REP1
│       │   │   ├── SAMPLE-A_REP1.deduplication.csv
│       │   │   ├── SAMPLE-A_REP2
│       │   │   ├── SAMPLE-A_REP2.deduplication.csv
│       │   │   ├── SAMPLE-B_REP1
│       │   │   ├── SAMPLE-B_REP1.deduplication.csv
│       │   │   ├── SAMPLE-B_REP2
│       │   │   └── SAMPLE-B_REP2.deduplication.csv
│       │   └── fastq_deduplication.csv
│       ├── deduplication_by_coordinate
│       │   ├── alignment_deduplication.csv
│       │   └── data
│       │       ├── SAMPLE-A_REP1_flashed.read.stats.csv
│       │       ├── SAMPLE-A_REP1_pe.read.stats.csv
│       │       ├── SAMPLE-A_REP2_flashed.read.stats.csv
│       │       ├── SAMPLE-A_REP2_pe.read.stats.csv
│       │       ├── SAMPLE-B_REP1_flashed.read.stats.csv
│       │       ├── SAMPLE-B_REP1_pe.read.stats.csv
│       │       ├── SAMPLE-B_REP2_flashed.read.stats.csv
│       │       └── SAMPLE-B_REP2_pe.read.stats.csv
│       ├── digest_genome
│       │   └── genome_digestion_statistics.txt
│       ├── digestion
│       │   ├── data
│       │   │   ├── SAMPLE-A_REP1_part0_flashed.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-A_REP1_part0_flashed.digestion.read.summary.csv
│       │   │   ├── SAMPLE-A_REP1_part0_flashed.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-A_REP1_part0_pe.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-A_REP1_part0_pe.digestion.read.summary.csv
│       │   │   ├── SAMPLE-A_REP1_part0_pe.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-A_REP2_part0_flashed.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-A_REP2_part0_flashed.digestion.read.summary.csv
│       │   │   ├── SAMPLE-A_REP2_part0_flashed.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-A_REP2_part0_pe.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-A_REP2_part0_pe.digestion.read.summary.csv
│       │   │   ├── SAMPLE-A_REP2_part0_pe.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-B_REP1_part0_flashed.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-B_REP1_part0_flashed.digestion.read.summary.csv
│       │   │   ├── SAMPLE-B_REP1_part0_flashed.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-B_REP1_part0_pe.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-B_REP1_part0_pe.digestion.read.summary.csv
│       │   │   ├── SAMPLE-B_REP1_part0_pe.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-B_REP2_part0_flashed.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-B_REP2_part0_flashed.digestion.read.summary.csv
│       │   │   ├── SAMPLE-B_REP2_part0_flashed.digestion.unfiltered.histogram.csv
│       │   │   ├── SAMPLE-B_REP2_part0_pe.digestion.filtered.histogram.csv
│       │   │   ├── SAMPLE-B_REP2_part0_pe.digestion.read.summary.csv
│       │   │   └── SAMPLE-B_REP2_part0_pe.digestion.unfiltered.histogram.csv
│       │   ├── fastq_digestion.csv
│       │   └── fastq_digestion.histogram.csv
│       ├── filtering
│       │   ├── alignment_filtering.csv
│       │   ├── alignment_filtering_slice.csv
│       │   ├── data
│       │   │   ├── SAMPLE-A_REP1_part0_flashed.read.stats.csv
│       │   │   ├── SAMPLE-A_REP1_part0_flashed.slice.stats.csv
│       │   │   ├── SAMPLE-A_REP1_part0_pe.read.stats.csv
│       │   │   ├── SAMPLE-A_REP1_part0_pe.slice.stats.csv
│       │   │   ├── SAMPLE-A_REP2_part0_flashed.read.stats.csv
│       │   │   ├── SAMPLE-A_REP2_part0_flashed.slice.stats.csv
│       │   │   ├── SAMPLE-A_REP2_part0_pe.read.stats.csv
│       │   │   ├── SAMPLE-A_REP2_part0_pe.slice.stats.csv
│       │   │   ├── SAMPLE-B_REP1_part0_flashed.read.stats.csv
│       │   │   ├── SAMPLE-B_REP1_part0_flashed.slice.stats.csv
│       │   │   ├── SAMPLE-B_REP1_part0_pe.read.stats.csv
│       │   │   ├── SAMPLE-B_REP1_part0_pe.slice.stats.csv
│       │   │   ├── SAMPLE-B_REP2_part0_flashed.read.stats.csv
│       │   │   ├── SAMPLE-B_REP2_part0_flashed.slice.stats.csv
│       │   │   ├── SAMPLE-B_REP2_part0_pe.read.stats.csv
│       │   │   └── SAMPLE-B_REP2_part0_pe.slice.stats.csv
│       │   └── logs
│       │       ├── SAMPLE-A_REP1_part0_flashed.log
│       │       ├── SAMPLE-A_REP1_part0_pe.log
│       │       ├── SAMPLE-A_REP2_part0_flashed.log
│       │       ├── SAMPLE-A_REP2_part0_pe.log
│       │       ├── SAMPLE-B_REP1_part0_flashed.log
│       │       ├── SAMPLE-B_REP1_part0_pe.log
│       │       ├── SAMPLE-B_REP2_part0_flashed.log
│       │       └── SAMPLE-B_REP2_part0_pe.log
│       ├── filtering_and_alignment_deduplication.csv
│       └── run_statistics.csv
├── logs
│   ├── align
│   │   ├── SAMPLE-A_REP1_0_flashed.log
│   │   ├── SAMPLE-A_REP1_0_flashed_sort.log
│   │   ├── SAMPLE-A_REP1_0_pe.log
│   │   ├── SAMPLE-A_REP1_0_pe_sort.log
│   │   ├── SAMPLE-A_REP2_0_flashed.log
│   │   ├── SAMPLE-A_REP2_0_flashed_sort.log
│   │   ├── SAMPLE-A_REP2_0_pe.log
│   │   ├── SAMPLE-A_REP2_0_pe_sort.log
│   │   ├── SAMPLE-B_REP1_0_flashed.log
│   │   ├── SAMPLE-B_REP1_0_flashed_sort.log
│   │   ├── SAMPLE-B_REP1_0_pe.log
│   │   ├── SAMPLE-B_REP1_0_pe_sort.log
│   │   ├── SAMPLE-B_REP2_0_flashed.log
│   │   ├── SAMPLE-B_REP2_0_flashed_sort.log
│   │   ├── SAMPLE-B_REP2_0_pe.log
│   │   └── SAMPLE-B_REP2_0_pe_sort.log
│   ├── annotate
│   │   ├── SAMPLE-A_REP1
│   │   │   ├── SAMPLE-A_REP1_part0_flashed.log
│   │   │   └── SAMPLE-A_REP1_part0_pe.log
│   │   ├── SAMPLE-A_REP2
│   │   │   ├── SAMPLE-A_REP2_part0_flashed.log
│   │   │   └── SAMPLE-A_REP2_part0_pe.log
│   │   ├── SAMPLE-B_REP1
│   │   │   ├── SAMPLE-B_REP1_part0_flashed.log
│   │   │   └── SAMPLE-B_REP1_part0_pe.log
│   │   └── SAMPLE-B_REP2
│   │       ├── SAMPLE-B_REP2_part0_flashed.log
│   │       └── SAMPLE-B_REP2_part0_pe.log
│   ├── bedgraph_norm
│   │   ├── SAMPLE-A_REP1_Slc25A37.log
│   │   ├── SAMPLE-A_REP2_Slc25A37.log
│   │   ├── SAMPLE-B_REP1_Slc25A37.log
│   │   └── SAMPLE-B_REP2_Slc25A37.log
│   ├── bedgraph_raw
│   │   ├── SAMPLE-A_REP1_Slc25A37.log
│   │   ├── SAMPLE-A_REP2_Slc25A37.log
│   │   ├── SAMPLE-B_REP1_Slc25A37.log
│   │   └── SAMPLE-B_REP2_Slc25A37.log
│   ├── bedgraph_to_bigwig
│   │   ├── A-B.mean-subtraction.Slc25A37.log
│   │   ├── A.mean-summary.Slc25A37.log
│   │   ├── B-A.mean-subtraction.Slc25A37.log
│   │   ├── B.mean-summary.Slc25A37.log
│   │   ├── SAMPLE-A_REP1_norm_Slc25A37.log
│   │   ├── SAMPLE-A_REP1_raw_Slc25A37.log
│   │   ├── SAMPLE-A_REP2_norm_Slc25A37.log
│   │   ├── SAMPLE-A_REP2_raw_Slc25A37.log
│   │   ├── SAMPLE-B_REP1_norm_Slc25A37.log
│   │   ├── SAMPLE-B_REP1_raw_Slc25A37.log
│   │   ├── SAMPLE-B_REP2_norm_Slc25A37.log
│   │   └── SAMPLE-B_REP2_raw_Slc25A37.log
│   ├── cis_and_trans_stats
│   │   ├── SAMPLE-A_REP1.log
│   │   ├── SAMPLE-A_REP2.log
│   │   ├── SAMPLE-B_REP1.log
│   │   └── SAMPLE-B_REP2.log
│   ├── compare_interactions
│   │   └── Slc25A37.log
│   ├── counts
│   │   ├── SAMPLE-A_REP1.log
│   │   ├── SAMPLE-A_REP2.log
│   │   ├── SAMPLE-B_REP1.log
│   │   └── SAMPLE-B_REP2.log
│   ├── deduplication_fastq
│   │   ├── SAMPLE-A_REP1.log
│   │   ├── SAMPLE-A_REP2.log
│   │   ├── SAMPLE-B_REP1.log
│   │   └── SAMPLE-B_REP2.log
│   ├── differential_interactions
│   │   └── Slc25A37.log
│   ├── digestion
│   │   ├── SAMPLE-A_REP1_0.log
│   │   ├── SAMPLE-A_REP2_0.log
│   │   ├── SAMPLE-B_REP1_0.log
│   │   └── SAMPLE-B_REP2_0.log
│   ├── fastqc
│   │   ├── SAMPLE-A_REP1_1.log
│   │   ├── SAMPLE-A_REP1_2.log
│   │   ├── SAMPLE-A_REP2_1.log
│   │   ├── SAMPLE-A_REP2_2.log
│   │   ├── SAMPLE-B_REP1_1.log
│   │   ├── SAMPLE-B_REP1_2.log
│   │   ├── SAMPLE-B_REP2_1.log
│   │   └── SAMPLE-B_REP2_2.log
│   ├── flash
│   │   ├── SAMPLE-A_REP1_0.log
│   │   ├── SAMPLE-A_REP2_0.log
│   │   ├── SAMPLE-B_REP1_0.log
│   │   └── SAMPLE-B_REP2_0.log
│   ├── make_report.log
│   ├── merge_counts
│   │   ├── SAMPLE-A_REP1.log
│   │   ├── SAMPLE-A_REP2.log
│   │   ├── SAMPLE-B_REP1.log
│   │   └── SAMPLE-B_REP2.log
│   ├── merge_stats_filtering_and_alignment_deduplication.log
│   ├── multiqc.log
│   ├── rebalance_partitions
│   │   ├── SAMPLE-A_REP1_flashed.log
│   │   ├── SAMPLE-A_REP1_pe.log
│   │   ├── SAMPLE-A_REP2_flashed.log
│   │   ├── SAMPLE-A_REP2_pe.log
│   │   ├── SAMPLE-B_REP1_flashed.log
│   │   ├── SAMPLE-B_REP1_pe.log
│   │   ├── SAMPLE-B_REP2_flashed.log
│   │   └── SAMPLE-B_REP2_pe.log
│   ├── remove_duplicate_coordinates
│   │   ├── SAMPLE-A_REP1_flashed.log
│   │   ├── SAMPLE-A_REP1_pe.log
│   │   ├── SAMPLE-A_REP2_flashed.log
│   │   ├── SAMPLE-A_REP2_pe.log
│   │   ├── SAMPLE-B_REP1_flashed.log
│   │   ├── SAMPLE-B_REP1_pe.log
│   │   ├── SAMPLE-B_REP2_flashed.log
│   │   └── SAMPLE-B_REP2_pe.log
│   ├── split
│   │   ├── SAMPLE-A_REP1.log
│   │   ├── SAMPLE-A_REP2.log
│   │   ├── SAMPLE-B_REP1.log
│   │   └── SAMPLE-B_REP2.log
│   └── trimming
│       ├── SAMPLE-A_REP1_0.log
│       ├── SAMPLE-A_REP2_0.log
│       ├── SAMPLE-B_REP1_0.log
│       └── SAMPLE-B_REP2_0.log
├── resources
│   ├── restriction_fragments
│   │   ├── genome.digest.bed.gz
│   │   └── genome.digest.log
│   └── viewpoints
│       └── viewpoints.bigBed
└── results
    ├── capcruncher_report.html
    ├── comparisons
    │   ├── bigwigs
    │   │   ├── A-B.mean-subtraction.Slc25A37.bigWig
    │   │   ├── A.mean-summary.Slc25A37.bigWig
    │   │   ├── B-A.mean-subtraction.Slc25A37.bigWig
    │   │   └── B.mean-summary.Slc25A37.bigWig
    │   └── counts_per_viewpoint
    │       └── norm
    │           └── Slc25A37.tsv
    ├── design_matrix.tsv
    ├── differential
    │   └── Slc25A37
    ├── figures
    │   ├── Slc25A37.pdf
    │   └── Slc25A37.toml
    ├── full_qc_report_data
    │   ├── multiqc_citations.txt
    │   ├── multiqc_data.json
    │   ├── multiqc_fastqc.txt
    │   ├── multiqc_general_stats.txt
    │   ├── multiqc.log
    │   ├── multiqc_samtools_stats.txt
    │   └── multiqc_sources.txt
    ├── full_qc_report.html
    ├── SAMPLE-A_REP1
    │   ├── bigwigs
    │   │   ├── norm
    │   │   │   └── SAMPLE-A_REP1_Slc25A37.bigWig
    │   │   └── raw
    │   │       └── SAMPLE-A_REP1_Slc25A37.bigWig
    │   ├── SAMPLE-A_REP1.bam
    │   ├── SAMPLE-A_REP1.bam.bai
    │   ├── SAMPLE-A_REP1.hdf5
    │   └── SAMPLE-A_REP1.parquet
    │       └── part-0.parquet
    ├── SAMPLE-A_REP2
    │   ├── bigwigs
    │   │   ├── norm
    │   │   │   └── SAMPLE-A_REP2_Slc25A37.bigWig
    │   │   └── raw
    │   │       └── SAMPLE-A_REP2_Slc25A37.bigWig
    │   ├── SAMPLE-A_REP2.bam
    │   ├── SAMPLE-A_REP2.bam.bai
    │   ├── SAMPLE-A_REP2.hdf5
    │   └── SAMPLE-A_REP2.parquet
    │       └── part-0.parquet
    ├── SAMPLE-B_REP1
    │   ├── bigwigs
    │   │   ├── norm
    │   │   │   └── SAMPLE-B_REP1_Slc25A37.bigWig
    │   │   └── raw
    │   │       └── SAMPLE-B_REP1_Slc25A37.bigWig
    │   ├── SAMPLE-B_REP1.bam
    │   ├── SAMPLE-B_REP1.bam.bai
    │   ├── SAMPLE-B_REP1.hdf5
    │   └── SAMPLE-B_REP1.parquet
    │       └── part-0.parquet
    └── SAMPLE-B_REP2
        ├── bigwigs
        │   ├── norm
        │   │   └── SAMPLE-B_REP2_Slc25A37.bigWig
        │   └── raw
        │       └── SAMPLE-B_REP2_Slc25A37.bigWig
        ├── SAMPLE-B_REP2.bam
        ├── SAMPLE-B_REP2.bam.bai
        ├── SAMPLE-B_REP2.hdf5
        └── SAMPLE-B_REP2.parquet
            └── part-0.parquet

142 directories, 324 files
```

## 2. Important files

The `capcruncher_output/results` directory contains the following files:

- `capcruncher_report.html`: the main report of the pipeline. It contains the
  results of the analysis and the figures.

- `full_qc_report.html`: the full QC report of the pipeline. It contains the
  results of the QC analysis and the figures.

- `design_matrix.tsv`: the design matrix used.

- `comparisons`: the results of the comparisons between the different
  conditions. The results are stored in the `bigwigs`
  directories (**Note**: Only for Capture-C and Tri-C)

- `differential`: the results of the differential analysis (**Note**: Only for
  Capture-C and Tri-C)

- `figures`: Plots generated by the pipeline. for each viewpoint at the coordinates provided in the configuration file.
    This also generates templates that can be used with the `capcruncher plot make-plot` command.

- `<SAMPLE_NAME>`: the results of the analysis for each sample. The directory contains the following files:

    - `bigwigs`: the bigwig files of the sample. The files are stored in the
      `raw` and `norm` directories. The `raw` directory contains the raw
      bigwig files. The `norm` directory contains the normalized bigwig files.
      **Note**: Only for Capture-C and Tri-C

    - `<SAMPLE_NAME>.bam`: the alignment file of the sample.

    - `<SAMPLE_NAME>.bam.bai`: the index of the alignment file of the sample.

    - `<SAMPLE_NAME>.hdf5`: Cooler formated groups within the HDF5 file per viewpoint. See [Cooler documentation](https://cooler.readthedocs.io/en/latest/) for more information on the format.

    - `<SAMPLE_NAME>.parquet`: This contains all of the data from the sample in a tabular format that can be accessed by any software that reads parquet files e.g. `pandas`, `polars`, [Arrow for R](https://github.com/apache/arrow/tree/main/r).


::: {.callout-note}
  Unlike regular cooler.hdf5 files, there are multiple groups per file, one per viewpoint. You can use any cooler supported tool but you will need to specify the group name. For example, to get the matrix for the viewpoint `Slc25A37` you can use the following command:

  ```bash
  cooler dump -t pixels -o Slc25A37.tsv <SAMPLE_NAME>.hdf5::Slc25A37`

  ```

:::
