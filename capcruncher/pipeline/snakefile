import os
import sys
import pathlib

import pandas as pd
import pyranges as pr
from snakemake.utils import min_version

import capcruncher.pipeline.utils as pipeline_utils

configfile: "config.yml"
# container: "library://asmith151/ngs-pipeline/ngs"

###########################
# Pipeline pre-run set-up #
###########################
pipeline_utils.format_config_dict(config)

### Experimental design ####

## Essential files ##
fastq_samples = pipeline_utils.GenericFastqSamples.from_files(list(pathlib.Path(".").glob("*.fastq*")))

VIEWPOINTS = config["analysis"]["viewpoints"]

## Analysis files ##
if os.path.exists(config["analysis"].get("design", None)):
    DESIGN = pd.read_table(config["analysis"]["design"], sep=r"\s+|,|\t", engine="python")
else:
    DESIGN = fastq_samples.experimental_design

N_SAMPLES = DESIGN["sample"].nunique()
ANALYSIS_METHOD = config["analysis"].get("method", "capture")
HIGH_NUMBER_OF_VIEWPOINTS = pipeline_utils.has_high_viewpoint_number(VIEWPOINTS, config)

## Optional ##
BLACKLIST = pipeline_utils.get_blacklist(config)
BINSIZES = pipeline_utils.get_binsizes(config)
PERFORM_BINNING = True if all(bs > 0 for bs in BINSIZES) else False
MAKE_HUB = pipeline_utils.is_on(config["hub"]["create"]) and not HIGH_NUMBER_OF_VIEWPOINTS
PERFORM_PLOTTING = pipeline_utils.can_perform_plotting(config)
FASTQ_DEDUPLICATE = config["deduplication"].get("pre-dedup", False)
COMPRESS_FASTQ = config["pipeline"].get("compression", 0) != 0

## Pipeline variables ##
SAMPLE_NAMES = DESIGN["sample"]
FASTQ_FILE_NAMES = [*fastq_samples.design["fq1"].apply(str).to_list(), 
                   *fastq_samples.design["fq2"].apply(str).to_list()]

include: "rules/digest.smk",
include: "rules/fastq.smk",
include: "rules/align.smk",
include: "rules/annotate.smk",


rule all:
    input:
        digested = "capcruncher_resources/restriction_enzyme_map/genome.digest.bed.gz",
        done = expand("{sample}.done", sample=SAMPLE_NAMES),
        


    
        

